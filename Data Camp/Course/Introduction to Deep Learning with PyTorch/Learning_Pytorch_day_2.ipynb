{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9dKO5DAUNU3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=nn.Sequential(\n",
        "    nn.Linear(20,256),\n",
        "    nn.Linear(256,10),\n",
        "    nn.Linear(10,1)\n",
        ")\n",
        "weight_0=model[0].weight\n",
        "bias_0=model[0].bias\n",
        "print(weight_0)\n",
        "print(bias_0)\n",
        "\n",
        "weight_1=model[1].weight\n",
        "bias_1=model[1].bias\n",
        "print(weight_1)\n",
        "print(bias_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYkdVkk5UP_T",
        "outputId": "b04d1c9c-9649-4e5f-b5d9-ebe7c54cc277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.1215, -0.0482, -0.0017,  ..., -0.1140, -0.1982, -0.1362],\n",
            "        [ 0.1528,  0.1614,  0.0591,  ...,  0.2201, -0.0790, -0.1612],\n",
            "        [ 0.1348,  0.1688, -0.1258,  ...,  0.0814, -0.1292, -0.1572],\n",
            "        ...,\n",
            "        [ 0.1093,  0.1516,  0.0393,  ...,  0.0854,  0.2216, -0.1397],\n",
            "        [ 0.1925,  0.0187,  0.1702,  ..., -0.1158, -0.1525, -0.0668],\n",
            "        [-0.1624, -0.0748, -0.1480,  ..., -0.1947, -0.0008, -0.2002]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2057,  0.0080,  0.1341,  0.0036, -0.0523,  0.0428,  0.0684, -0.0112,\n",
            "        -0.1430, -0.0734, -0.1220, -0.0786, -0.1698,  0.0700, -0.1221,  0.0084,\n",
            "        -0.0827,  0.0080,  0.0372, -0.2170, -0.2163, -0.0772,  0.1729, -0.0685,\n",
            "         0.1682,  0.1936, -0.2165, -0.0309,  0.0665,  0.1956,  0.0800,  0.0479,\n",
            "        -0.0821, -0.0776, -0.1079, -0.1116,  0.0061,  0.1513, -0.0087, -0.0176,\n",
            "         0.1170,  0.1200,  0.1298,  0.0201,  0.0356,  0.0731, -0.1647,  0.1702,\n",
            "        -0.1708,  0.0251,  0.1761,  0.0630, -0.2062,  0.0564, -0.0699,  0.1521,\n",
            "         0.0666, -0.0157,  0.0380,  0.1066, -0.0004,  0.2137,  0.1270,  0.1521,\n",
            "        -0.1113, -0.1511,  0.0725, -0.1694, -0.0309,  0.1614, -0.1088,  0.0559,\n",
            "        -0.1622, -0.0355, -0.1203, -0.0169, -0.2087,  0.0525, -0.1108,  0.0082,\n",
            "         0.2167, -0.0599, -0.0663, -0.1397,  0.0777, -0.0797,  0.1772, -0.0463,\n",
            "        -0.1217, -0.0464,  0.0545, -0.1639, -0.1805, -0.1964, -0.1722, -0.0364,\n",
            "         0.1529,  0.1249, -0.1255, -0.1149, -0.1583, -0.0024,  0.2061,  0.1127,\n",
            "        -0.1725, -0.1057,  0.2004, -0.1501,  0.0326, -0.1235,  0.2123,  0.0705,\n",
            "        -0.1591,  0.1753,  0.0863, -0.0938,  0.1879, -0.0778, -0.2149, -0.1811,\n",
            "         0.2203,  0.1412,  0.0560,  0.1147, -0.0768,  0.0875, -0.1944, -0.1428,\n",
            "        -0.1254, -0.1361, -0.0362,  0.1755,  0.0355,  0.1914,  0.0757, -0.1634,\n",
            "        -0.1580,  0.1653,  0.2142,  0.0947, -0.0868, -0.0202,  0.2198, -0.0491,\n",
            "        -0.0267, -0.0743, -0.1247,  0.2083,  0.2208,  0.0496,  0.1729,  0.1292,\n",
            "        -0.0620, -0.0359,  0.1512, -0.2033, -0.0205,  0.1703,  0.0150,  0.0127,\n",
            "         0.1203, -0.0335, -0.0838,  0.1185,  0.1611, -0.2190,  0.0220, -0.1946,\n",
            "        -0.1127, -0.1568,  0.0621,  0.0943,  0.0091,  0.0625, -0.0945,  0.0115,\n",
            "         0.0476, -0.0314,  0.1128,  0.1143,  0.2016, -0.2020, -0.1848, -0.1171,\n",
            "        -0.0851,  0.1854, -0.0272, -0.1406, -0.0753, -0.1647, -0.0581, -0.1253,\n",
            "         0.2153, -0.1474, -0.0401, -0.2143,  0.2205, -0.1164,  0.1083,  0.1455,\n",
            "        -0.0936, -0.1970, -0.0868,  0.1540,  0.1169,  0.0746, -0.1265, -0.0890,\n",
            "         0.1894,  0.1105,  0.0559,  0.1688,  0.0641,  0.0387,  0.0191,  0.1367,\n",
            "         0.0900, -0.1278,  0.0901,  0.1038, -0.0570, -0.2163, -0.0306,  0.0576,\n",
            "         0.1609, -0.2001,  0.0074,  0.0772, -0.1798,  0.0025, -0.1799, -0.0823,\n",
            "         0.1814,  0.1226, -0.0090,  0.0325,  0.0998,  0.1500,  0.1990, -0.1263,\n",
            "         0.2229,  0.1668,  0.2129, -0.2067,  0.0487,  0.0786, -0.1890,  0.0405,\n",
            "        -0.0417,  0.0485,  0.1627, -0.1581,  0.1846, -0.2220, -0.1896, -0.2133],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0388, -0.0611,  0.0590,  ...,  0.0082, -0.0084,  0.0454],\n",
            "        [-0.0542,  0.0159, -0.0010,  ...,  0.0412,  0.0186, -0.0431],\n",
            "        [ 0.0398,  0.0037,  0.0441,  ...,  0.0621,  0.0113,  0.0283],\n",
            "        ...,\n",
            "        [ 0.0403,  0.0562,  0.0423,  ..., -0.0408, -0.0509, -0.0137],\n",
            "        [-0.0013,  0.0407, -0.0189,  ..., -0.0590,  0.0056, -0.0598],\n",
            "        [ 0.0338,  0.0357,  0.0380,  ..., -0.0471,  0.0024, -0.0243]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0429, -0.0385,  0.0157, -0.0201, -0.0150, -0.0585,  0.0340, -0.0293,\n",
            "        -0.0390, -0.0426], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weight0 = model[0].weight\n",
        "weight1 = model[1].weight\n",
        "weight2 = model[2].weight\n",
        "\n",
        "grads0 = model[0].weight.grad\n",
        "grads1 = model[1].weight.grad\n",
        "grads2 = model[2].weight.grad\n",
        "\n",
        "print(grads0)\n",
        "print(grads1)\n",
        "print(grads2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8HpQ5Bdhz1b",
        "outputId": "199f7479-eb98-4ca7-8750-dece0abaf42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.001\n",
        "\n",
        "weight0 = weight0 - lr *grads0\n",
        "weight1 = weight1 - lr *grads1\n",
        "weight2 = weight2 - lr *grads2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "90qzdpy1iNXk",
        "outputId": "b5ba18fd-c892-4892-9e54-5a3fbf7bb609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-603912995.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweight0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrads0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mweight1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrads1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mweight2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrads2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "ghMeF12Skdzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "labels = torch.tensor([0, 1, 0])\n",
        "dataset = TensorDataset(features, labels)\n",
        "dataloader= DataLoader(dataset, batch_size=2, shuffle=True)\n",
        "for x,y in dataloader:\n",
        "  print(x,y)\n",
        "a,b=dataset[0]\n",
        "print(a,b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVvfGMZ2lKH4",
        "outputId": "b158eb49-6bf1-4871-c29b-6f7c9108c3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]]) tensor([0, 1])\n",
            "tensor([[5., 6.]]) tensor([0])\n",
            "tensor([1., 2.]) tensor(0)\n"
          ]
        }
      ]
    }
  ]
}